{"cells":[{"cell_type":"code","source":["#dbutils.fs.rm(\"FileStore/tables/train.csv\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Imports\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import lower\nimport re\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import ArrayType\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml.feature import Word2Vec\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Read the data\nsentimentdf = spark.sql(\"SELECT * FROM train_csv\")\ndisplay(sentimentdf)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Data cleaning\ndef text_cleaning(text):\n    text = text.lower()\n    text_content = text.split()    \n    word_list = \"\"\n    for i in text_content:\n        x = 0\n        digits = re.findall('[0-9]', i)\n        underscore = re.findall('_', i)\n        if (('http' not in i) and ('@' not in i) and ('<.*?>' not in i) and (len(digits) < 1) and (len(underscore) < 1)):\n            j = re.sub(r'[^\\w\\s]','',i)\n            word_list += j + \" \"\n        \n    return word_list \n\ndef data_cleaning(sentimentdf, SentimentText1):\n  review_udf = udf(text_cleaning,StringType())\n  df = sentimentdf.withColumn(\"CleanSentimentText\",review_udf(sentimentdf[SentimentText1]))\n  return df  \n  \nclean_df = data_cleaning(sentimentdf, \"SentimentText\")\nclean_df.show(2)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Tokenize\ndef tokenize(df1, CleanSentimentText1):\n  tokenizer = Tokenizer(inputCol=CleanSentimentText1, outputCol=\"tokens1\")\n  tokenized = tokenizer.transform(df1)\n  return tokenized\n\ntokenized_df = tokenize(clean_df, \"CleanSentimentText\")\ndisplay(tokenized_df)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Remove space\ndef clean_string(text1):\n  wordGrabber = [] \n  for element in text1:\n    if (element != \"\"):\n      wordGrabber.append(element)\n  return wordGrabber\n  \n\ndef remove_space(sentimentdf1, SentimentText2):\n  token_udf = udf(clean_string,ArrayType(StringType()))\n  token_df = sentimentdf1.withColumn(\"CleanTokens\",token_udf(sentimentdf1[SentimentText2]))\n  return token_df\n\nclean_df1 = remove_space(tokenized_df, \"tokens1\")\ndisplay(clean_df1)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Removed stop words\n#inp_array = df.withColumn(col(\"ItemDescription\"), ArrayType(StringType()))\ndef stopwords_remover(df,tokens):\n  remover = StopWordsRemover(inputCol=tokens, outputCol=\"Tweets\")\n  tweetsData = remover.transform(df)\n  return tweetsData  \n\ntweetsData = stopwords_remover(clean_df1, \"CleanTokens\")\ndisplay(tweetsData)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["import pyspark.sql.functions as F\ndf = tweetsData.withColumn(\"size\", F.size(F.col(\"Tweets\")))\ndf_filtered = df.filter(F.col(\"size\") >= 1)\ndisplay(df_filtered)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["twitter_df = df_filtered.select(\"Tweets\", \"Sentiment\")\ndisplay(twitter_df)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["g = twitter_df.where(col(\"Sentiment\").isNull())\ng.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["'''Renamed the column Price to Label'''\ndf1 = twitter_df.withColumn(\"label\", twitter_df.Sentiment.cast(IntegerType()))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["g = df1.where(col(\"Tweets\").isNull())\ng.count()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["clean_df = df1.filter(df1.label.isNotNull())\ndisplay(clean_df)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Learn a mapping from words to Vectors.\ndef vector_representation(df, tweets):\n  word2Vec = Word2Vec(vectorSize=10, minCount=5, inputCol=tweets, outputCol=\"features\")\n  model = word2Vec.fit(df)\n  twitter_datamodel = model.transform(df)\n  return twitter_datamodel\n  \nvector_df = vector_representation(clean_df, \"Tweets\")\nvector_df.show(2)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["display(vector_df)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["df2 = vector_df.filter(vector_df.label.isNotNull())\ng = df2.where(col(\"label\").isNull())\ng.count()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["final_twitterdf = vector_df.select(\"Tweets\",\"features\",\"label\")\ndisplay(final_twitterdf)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Divide the data into 70% and 30%\ntraining, test = final_twitterdf.randomSplit(weights=[0.7, 0.3])\ntraining.cache()\ntest.cache()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["display(training)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Predict using Random Forest Classifier and evaluation using Multiclass Classification Evaluator \ndef predict(trainData, testData):\n  # Train a RandomForest model.\n  rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n\n  # Train model.  This also runs the indexers.\n  model = rf.fit(trainData)\n\n  # Make predictions.\n  predictions = model.transform(testData)\n  return predictions\n  \npred = predict(training, test)\n# Select example rows to display.\ndisplay(pred)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n  labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(pred)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["predicted_model = pred.select(\"label\",\"prediction\",\"features\")\ndisplay(predicted_model)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Print the accuracy\nprint(\"Test Error = %g\" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Read and preprocess the streamed data from Twitter\nstreamedtdf = spark.sql(\"SELECT Tweet FROM streamtweets\")\nstreamed_clean_df = data_cleaning(streamedtdf, \"Tweet\")\nstream_tokenized_df = tokenize(streamed_clean_df, \"CleanSentimentText\")\nstream_remove_space = remove_space(stream_tokenized_df,\"tokens1\")\nstreamTweetsData = stopwords_remover(stream_remove_space, \"CleanTokens\")\nstreamTwitter_df = streamTweetsData.select(\"Tweets\")\nstreamVector_df = vector_representation(streamTwitter_df, \"Tweets\")\nstreamVector_df.show(2)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Prediction on Twitter streamed data\nstreampred = predict(final_twitterdf, streamVector_df)\ndisplay(streampred)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Display Results\nfinalresult = streampred.select(\"Tweets\",\"prediction\")\ndisplay(finalresult)"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"Sentiment Analysis on Twitter data","notebookId":985754373168602},"nbformat":4,"nbformat_minor":0}
